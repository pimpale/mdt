{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metadrive\n",
    "\n",
    "We now introduce the environment we will be using for this notebook: [Metadrive](https://github.com/metadriverse/metadrive)\n",
    "\n",
    "Check out the notebook [here](../quickstart.ipynb) for a quick introduction to Metadrive as well as how to install it."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get started by doing a bunch of imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully registered the following environments: ['MetaDrive-validation-v0', 'MetaDrive-10env-v0', 'MetaDrive-100envs-v0', 'MetaDrive-1000envs-v0', 'SafeMetaDrive-validation-v0', 'SafeMetaDrive-10env-v0', 'SafeMetaDrive-100envs-v0', 'SafeMetaDrive-1000envs-v0', 'MARLTollgate-v0', 'MARLBottleneck-v0', 'MARLRoundabout-v0', 'MARLIntersection-v0', 'MARLParkingLot-v0', 'MARLMetaDrive-v0'].\n"
     ]
    }
   ],
   "source": [
    "# We need to import metadrive to register the environments\n",
    "import metadrive\n",
    "import gymnasium as gym\n",
    "import typing\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test out the environment by creating an instance of it and taking a random action at each timestep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fidgetsinner/venvs/metadrive/lib/python3.11/site-packages/gymnasium/utils/passive_env_checker.py:210: DeprecationWarning: WARN: Current gymnasium version requires that `Env.reset` can be passed `options` to allow the environment initialisation to be passed additional information.\n",
      "  logger.deprecation(\n",
      "Known pipe types:\n",
      "  glxGraphicsPipe\n",
      "(1 aux display modules not yet loaded.)\n",
      "INFO:/home/fidgetsinner/myworkspace/metadrive/metadrive/envs/base_env.py:Episode ended! Index: 0 Reason: max step \n"
     ]
    }
   ],
   "source": [
    "# horizon represents the number of steps in an episode before truncation\n",
    "env = gym.make(\"MetaDrive-validation-v0\", config={\"use_render\": True, \"horizon\": 100})\n",
    "env.reset()\n",
    "while True:\n",
    "    obs, reward, terminated, truncated, info = env.step(env.action_space.sample())\n",
    "    if terminated or truncated:\n",
    "        break\n",
    "env.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metadrive uses the [Farama Gymnasium](https://gymnasium.farama.org/), which has a standard API for interacting with environments. There are a couple of functions and properties that are good to know about:\n",
    "1. `reset()`: Resets the environment to its initial state and returns the initial observation.\n",
    "    * Documentation: https://gymnasium.farama.org/api/env/#gymnasium.Env.reset\n",
    "2. `step(action)`: Takes an action and returns the next observation, the reward for taking the action, whether the episode is terminated, whether the episode is truncated (ran out of time), and any additional information.\n",
    "    * Documentation: https://gymnasium.farama.org/api/env/#gymnasium.Env.step\n",
    "3. `close()`: Closes the environment.\n",
    "    * Documentation: https://gymnasium.farama.org/api/env/#g1ymnasium.Env.close\n",
    "4. `action_space`: The action space of the environment, which tells us the shape and bounds of the action space.\n",
    "    * Documentation: https://gymnasium.farama.org/api/env/#gymnasium.Env.action_space\n",
    "5. `observation_space`: The observation space of the environment, which tells us the shape and bounds of the observation space.\n",
    "    * Documentation: https://gymnasium.farama.org/api/env/#gymnasium.Env.observation_space"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a closer look at what our observation and action spaces are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation Space: Box(-0.0, 1.0, (259,), float32)\n",
      "Action Space: Box(-1.0, 1.0, (2,), float32)\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"MetaDrive-validation-v0\", config={\"use_render\": False, \"horizon\": 100})\n",
    "print(\"Observation Space:\", env.observation_space)\n",
    "print(\"Action Space:\", env.action_space)\n",
    "env.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Box spaces represent a continuous space. As the documentation states, a Box represents the Cartesian product of $n$ closed intervals.\n",
    "\n",
    "For our observation space, we have a 259 dimensional vector, where each element is in the range $[0.0, 1.0]$.\n",
    "* Documentation: https://metadrive-simulator.readthedocs.io/en/latest/observation.html\n",
    "\n",
    "For the action space, we have a 2 dimensional vector, where each element is in the range $[-1.0, 1.0]$. The first element represents the steering angle, and the second element represents the throttle.\n",
    "* Documentation: https://metadrive-simulator.readthedocs.io/en/latest/action_and_dynamics.html\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's one problem you might see here: we previously stated that we were focusing on the discrete case of the policy gradient. Yet our action space seems to be continuous. So what gives?\n",
    "\n",
    "The answer is that we are going to discretize our action space. We will discretize the steering angle into 2 bins, and the throttle into 2 bins. This will give us a total of 4 actions. We'll write a function to convert our discrete action into a continuous action, which we can provide to the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_ACTIONS = 4\n",
    "\n",
    "def discrete2continuous(action:int) -> npt.NDArray[np.float32]:\n",
    "    \"\"\"\n",
    "    Convert discrete action to continuous action\n",
    "    \"\"\"\n",
    "    assert 0 <= action < 4\n",
    "    throttle_magnitude = 1.0\n",
    "    steering_magnitude = 0.6\n",
    "    match action:\n",
    "        case 0:\n",
    "            return np.array([throttle_magnitude, 0.0])\n",
    "        case 1:\n",
    "            return np.array([0.0, steering_magnitude])\n",
    "        case 2:\n",
    "            return np.array([0.0, -steering_magnitude])\n",
    "        case 3:\n",
    "            return np.array([-throttle_magnitude, 0.0])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this, we can write a function to collect a trajectory given a policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_trajectory(env:gym.Env, policy:typing.Callable[[npt.NDArray], int]) -> tuple[list[npt.NDArray], list[int], list[float]]:\n",
    "    \"\"\"\n",
    "    Collect a trajectory from the environment using the given policy\n",
    "    \"\"\"\n",
    "    observations = []\n",
    "    actions = []\n",
    "    rewards = []\n",
    "    obs, info = env.reset()\n",
    "    \n",
    "    while True:\n",
    "        observations.append(obs)\n",
    "        action = policy(obs)\n",
    "        actions.append(action)\n",
    "        obs, reward, terminated, truncated, info = env.step(discrete2continuous(action))\n",
    "        rewards.append(reward)\n",
    "        if terminated or truncated:\n",
    "            break\n",
    "\n",
    "    return observations, actions, rewards"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test out the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ":task(warning): Creating implicit AsyncTaskChain default for AsyncTaskManager TaskManager\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:/home/fidgetsinner/myworkspace/metadrive/metadrive/envs/base_env.py:Episode ended! Index: 0 Reason: max step \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations: [array([0.09722222, 0.4861111 , 0.5       , 0.01234568, 0.5       ,\n",
      "       0.5       , 0.5       , 0.        , 0.5       , 0.55      ,\n",
      "       0.465     , 0.        , 0.5       , 0.5       , 0.95      ,\n",
      "       0.46500003, 0.        , 0.5       , 0.5       , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        ], dtype=float32), array([0.09722222, 0.4861111 , 0.5       , 0.01266881, 0.5083333 ,\n",
      "       1.        , 0.5       , 0.        , 0.5       , 0.55      ,\n",
      "       0.465     , 0.        , 0.5       , 0.5       , 0.95      ,\n",
      "       0.46500003, 0.        , 0.5       , 0.5       , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        ], dtype=float32), array([0.09721348, 0.48611987, 0.4999353 , 0.01448778, 0.5083333 ,\n",
      "       1.        , 0.5       , 0.0012943 , 0.49996504, 0.54998   ,\n",
      "       0.46499202, 0.        , 0.5       , 0.5       , 0.9499778 ,\n",
      "       0.46494064, 0.        , 0.5       , 0.5       , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        ], dtype=float32), array([0.09720826, 0.48612508, 0.4998725 , 0.01400252, 0.49166667,\n",
      "       0.        , 0.5       , 0.00125568, 0.49994415, 0.5499186 ,\n",
      "       0.46498498, 0.        , 0.5       , 0.5       , 0.94987714,\n",
      "       0.46488473, 0.        , 0.5       , 0.5       , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        ], dtype=float32), array([9.7204842e-02, 4.8612848e-01, 4.9986005e-01, 2.1367053e-02,\n",
      "       5.0000000e-01, 5.0000000e-01, 8.0000001e-01, 2.4900559e-04,\n",
      "       4.9993050e-01, 5.4983866e-01, 4.6498305e-01, 0.0000000e+00,\n",
      "       5.0000000e-01, 5.0000000e-01, 9.4979596e-01, 4.6487215e-01,\n",
      "       0.0000000e+00, 5.0000000e-01, 5.0000000e-01, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00], dtype=float32), array([9.7201139e-02, 4.8613220e-01, 4.9985951e-01, 1.4971352e-02,\n",
      "       5.0000000e-01, 5.0000000e-01, 2.0000000e-01, 1.0653028e-05,\n",
      "       4.9991566e-01, 5.4976434e-01, 4.6498227e-01, 0.0000000e+00,\n",
      "       5.0000000e-01, 5.0000000e-01, 9.4974226e-01, 4.6487015e-01,\n",
      "       0.0000000e+00, 5.0000000e-01, 5.0000000e-01, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00], dtype=float32), array([0.09722821, 0.4861051 , 0.4999835 , 0.01287576, 0.49166667,\n",
      "       0.        , 0.5       , 0.0024794 , 0.50002396, 0.54976904,\n",
      "       0.4649994 , 0.        , 0.5       , 0.5       , 0.9497578 ,\n",
      "       0.464986  , 0.        , 0.5       , 0.5       , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        ], dtype=float32), array([0.09725841, 0.48607492, 0.5001383 , 0.02013834, 0.5       ,\n",
      "       0.5       , 0.8       , 0.00309592, 0.5001447 , 0.5497296 ,\n",
      "       0.46502033, 0.        , 0.5       , 0.5       , 0.9497226 ,\n",
      "       0.46513134, 0.        , 0.5       , 0.5       , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        ], dtype=float32), array([9.7262487e-02, 4.8607084e-01, 5.0016886e-01, 1.7093815e-02,\n",
      "       5.0000000e-01, 5.0000000e-01, 2.0000000e-01, 6.1119546e-04,\n",
      "       5.0016105e-01, 5.4967546e-01, 4.6502405e-01, 0.0000000e+00,\n",
      "       5.0000000e-01, 5.0000000e-01, 9.4966489e-01, 4.6515939e-01,\n",
      "       0.0000000e+00, 5.0000000e-01, 5.0000000e-01, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00], dtype=float32), array([0.09720641, 0.48612693, 0.49993283, 0.01457713, 0.49166667,\n",
      "       0.        , 0.5       , 0.00472045, 0.49993673, 0.54970706,\n",
      "       0.46499062, 0.        , 0.5       , 0.5       , 0.94968766,\n",
      "       0.46493793, 0.        , 0.5       , 0.5       , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        ], dtype=float32)]\n",
      "Actions: [0, 0, 3, 1, 2, 3, 1, 2, 3, 3]\n",
      "Rewards: [3.271655938232812e-05, 0.0017418133095614286, 0.005370524954281802, 0.00880554579522801, 0.007955325417773933, 0.000583436364116107, 0.005870183993461035, 0.006064511870900822, -0.004693117355700312, -0.003885300389886925]\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"MetaDrive-validation-v0\", config={\"use_render\": False, \"horizon\": 100})\n",
    "# horizon is the max number of steps in a trajectory\n",
    "def random_policy(obs:npt.NDArray) -> int:\n",
    "    \"\"\"\n",
    "    A random policy that returns a random action\n",
    "    \"\"\"\n",
    "    return np.random.randint(0, NUM_ACTIONS)\n",
    "\n",
    "obs, actions, rewards = collect_trajectory(env, random_policy)\n",
    "# print the first 10 observations, actions, and rewards\n",
    "print(\"Observations:\", obs[:10])\n",
    "print(\"Actions:\", actions[:10])\n",
    "print(\"Rewards:\", rewards[:10])\n",
    "env.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our `collect_trajectory` function allows us to gather rewards from the trajectory. However, recall that what we'll actually train the network on is the reward-to-go. Let's now create the function./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAMMA = 0.9\n",
    "\n",
    "def rewards_to_go(trajectory_rewards: list[float]) -> list[float]:\n",
    "    \"\"\"\n",
    "    Computes the gamma discounted reward-to-go for each state in the trajectory.\n",
    "    \"\"\"\n",
    "\n",
    "    trajectory_len = len(trajectory_rewards)\n",
    "\n",
    "    v_batch = np.zeros(trajectory_len)\n",
    "\n",
    "    v_batch[-1] = trajectory_rewards[-1]\n",
    "\n",
    "    # Use GAMMA to decay the advantage\n",
    "    for t in reversed(range(trajectory_len - 1)):\n",
    "        v_batch[t] = trajectory_rewards[t] + GAMMA * v_batch[t + 1]\n",
    "\n",
    "    return list(v_batch)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, now that we have a function that lets us go from policies to trajectories, we should work on creating a neural network based policy. The network should take in an observation, and return a probability for each number between 0 and 9.\n",
    "\n",
    "We're going to keep the network fairly small for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# policy network\n",
    "class Policy(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(259, 128)\n",
    "        self.fc2 = nn.Linear(128, NUM_ACTIONS)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        # output in (Batch, Width)\n",
    "        output = F.softmax(x, dim=1)\n",
    "        return output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a policy function that allows us to sample an action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deviceof(m: nn.Module) -> torch.device:\n",
    "    \"\"\"\n",
    "    Get the device of the given module\n",
    "    \"\"\"\n",
    "    return next(m.parameters()).device\n",
    "\n",
    "def nn_policy(net:Policy, obs:npt.NDArray) -> int:\n",
    "    \"\"\"\n",
    "    A neural network policy that returns an action based on the given observation\n",
    "    \"\"\"\n",
    "    # convert observation to a tensor\n",
    "    obs_tensor = torch.from_numpy(obs).float().to(deviceof(net))\n",
    "    # add batch dimension\n",
    "    obs_tensor = obs_tensor.unsqueeze(0)\n",
    "    # get the action probabilities\n",
    "    action_probs = net(obs_tensor)\n",
    "    # sample an action from the action probabilities\n",
    "    action = torch.multinomial(action_probs, 1)\n",
    "    return action.item()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test it out (untrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ":task(warning): Creating implicit AsyncTaskChain default for AsyncTaskManager TaskManager\n",
      "INFO:/home/fidgetsinner/myworkspace/metadrive/metadrive/envs/base_env.py:Episode ended! Index: 0 Reason: max step \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations: [array([0.09722222, 0.4861111 , 0.5       , 0.01234568, 0.5       ,\n",
      "       0.5       , 0.5       , 0.        , 0.5       , 0.55      ,\n",
      "       0.465     , 0.        , 0.5       , 0.5       , 0.95      ,\n",
      "       0.46500003, 0.        , 0.5       , 0.5       , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        ], dtype=float32), array([0.09722222, 0.4861111 , 0.5       , 0.01266881, 0.5083333 ,\n",
      "       1.        , 0.5       , 0.        , 0.5       , 0.55      ,\n",
      "       0.465     , 0.        , 0.5       , 0.5       , 0.95      ,\n",
      "       0.46500003, 0.        , 0.5       , 0.5       , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        ], dtype=float32), array([9.7219124e-02, 4.8611420e-01, 4.9997517e-01, 2.0026203e-02,\n",
      "       5.0000000e-01, 5.0000000e-01, 8.0000001e-01, 4.9667951e-04,\n",
      "       4.9998760e-01, 5.4995269e-01, 4.6499696e-01, 0.0000000e+00,\n",
      "       5.0000000e-01, 5.0000000e-01, 9.4995147e-01, 4.6497720e-01,\n",
      "       0.0000000e+00, 5.0000000e-01, 5.0000000e-01, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00], dtype=float32), array([9.7217135e-02, 4.8611620e-01, 4.9996623e-01, 1.3340503e-02,\n",
      "       5.0000000e-01, 5.0000000e-01, 2.0000000e-01, 1.7843174e-04,\n",
      "       4.9997965e-01, 5.4985934e-01, 4.6499574e-01, 0.0000000e+00,\n",
      "       5.0000000e-01, 5.0000000e-01, 9.4982123e-01, 4.6496880e-01,\n",
      "       0.0000000e+00, 5.0000000e-01, 5.0000000e-01, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00], dtype=float32), array([9.7212419e-02, 4.8612091e-01, 4.9995425e-01, 1.3567443e-02,\n",
      "       4.9166667e-01, 0.0000000e+00, 5.0000000e-01, 2.3968446e-04,\n",
      "       4.9996078e-01, 5.4983288e-01, 4.6499366e-01, 0.0000000e+00,\n",
      "       5.0000000e-01, 5.0000000e-01, 9.4978112e-01, 4.6495685e-01,\n",
      "       0.0000000e+00, 5.0000000e-01, 5.0000000e-01, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00], dtype=float32), array([9.7206064e-02, 4.8612726e-01, 4.9993283e-01, 1.3195242e-02,\n",
      "       4.9166667e-01, 0.0000000e+00, 5.0000000e-01, 4.2876892e-04,\n",
      "       4.9993536e-01, 5.4986131e-01, 4.6499038e-01, 0.0000000e+00,\n",
      "       5.0000000e-01, 5.0000000e-01, 9.4983763e-01, 4.6493658e-01,\n",
      "       0.0000000e+00, 5.0000000e-01, 5.0000000e-01, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00], dtype=float32), array([9.7209796e-02, 4.8612353e-01, 4.9994847e-01, 1.8862626e-02,\n",
      "       5.0000000e-01, 5.0000000e-01, 8.0000001e-01, 3.1292142e-04,\n",
      "       4.9995029e-01, 5.4984480e-01, 4.6499261e-01, 0.0000000e+00,\n",
      "       5.0000000e-01, 5.0000000e-01, 9.4983637e-01, 4.6495128e-01,\n",
      "       0.0000000e+00, 5.0000000e-01, 5.0000000e-01, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00], dtype=float32), array([9.7211570e-02, 4.8612177e-01, 4.9995258e-01, 1.5410245e-02,\n",
      "       5.0000000e-01, 5.0000000e-01, 2.0000000e-01, 8.2557948e-05,\n",
      "       4.9995741e-01, 5.4979140e-01, 4.6499336e-01, 0.0000000e+00,\n",
      "       5.0000000e-01, 5.0000000e-01, 9.4978368e-01, 4.6495542e-01,\n",
      "       0.0000000e+00, 5.0000000e-01, 5.0000000e-01, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00], dtype=float32), array([9.7212106e-02, 4.8612124e-01, 4.9995267e-01, 1.7956378e-02,\n",
      "       5.0000000e-01, 5.0000000e-01, 2.0000000e-01, 1.3328004e-06,\n",
      "       4.9995953e-01, 5.4974306e-01, 4.6499348e-01, 0.0000000e+00,\n",
      "       5.0000000e-01, 5.0000000e-01, 9.4973385e-01, 4.6495560e-01,\n",
      "       0.0000000e+00, 5.0000000e-01, 5.0000000e-01, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
      "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00], dtype=float32), array([0.09721205, 0.4861213 , 0.49995267, 0.01541024, 0.5       ,\n",
      "       0.5       , 0.2       , 0.        , 0.49995932, 0.5497335 ,\n",
      "       0.46499345, 0.        , 0.5       , 0.5       , 0.9497209 ,\n",
      "       0.46495557, 0.        , 0.5       , 0.5       , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        ], dtype=float32)]\n",
      "Actions: [0, 1, 2, 3, 3, 1, 2, 2, 2, 0]\n",
      "Rewards: [3.271655938232812e-05, 0.005322864831844196, 0.00891076926450672, 0.002513134575732593, -0.002556613270116008, 0.0026148731877332684, 0.005687103160402489, 0.005384615493833419, 0.0012229531204059705, -0.0014458241447145796]\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"MetaDrive-validation-v0\", config={\"use_render\": False, \"horizon\": 100})\n",
    "\n",
    "policy = Policy()\n",
    "obs, actions, rewards = collect_trajectory(env, lambda obs: nn_policy(policy, obs))\n",
    "# print the first 10 observations, actions, and rewards\n",
    "print(\"Observations:\", obs[:10])\n",
    "print(\"Actions:\", actions[:10])\n",
    "print(\"Rewards:\", rewards[:10])\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, it performs basically random actions, since it hasn't been trained yet."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now work on the meat of the problem: the Policy Gradient algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENTROPY_BONUS = 0.1\n",
    "\n",
    "def compute_policy_gradient_loss(\n",
    "    # Current policy network's probability of choosing an action\n",
    "    # in (Batch, Action)\n",
    "    pi_theta_given_st: torch.Tensor,\n",
    "    # One hot encoding of which action was chosen\n",
    "    # in (Batch, Action)\n",
    "    a_t: torch.Tensor,\n",
    "    # Rewards To Go for the chosen action\n",
    "    # in (Batch,)\n",
    "    R_t: torch.Tensor,\n",
    ") -> torch.Tensor:\n",
    "    r\"\"\"\n",
    "    Computes the policy gradient loss for a vector of examples, and reduces with mean.\n",
    "\n",
    "    The standard policy gradient is given by the expected value over trajectories of:\n",
    "\n",
    "    :math:`\\sum_{t=0}^{T} \\nabla_{\\theta} (\\log \\pi_{\\theta}(a_t|s_t))R_t`\n",
    "    \n",
    "    where:\n",
    "    * :math:`\\pi_{\\theta}(a_t|s_t)` is the current policy's probability to perform action :math:`a_t` given :math:`s_t`\n",
    "    * :math:`R_t` is the rewards-to-go from the state at time t to the end of the episode from which it came.\n",
    "    \"\"\"\n",
    "\n",
    "    # here, the multiplication and sum is in order to extract the\n",
    "    # in (Batch,)\n",
    "    pi_theta_at_given_st = torch.sum(pi_theta_given_st * a_t, 1)\n",
    "\n",
    "    # Note: this loss has doesn't actually represent whether the action was good or bad\n",
    "    # it is a dummy loss, that is only used to compute the gradient\n",
    "\n",
    "    # Recall that the policy gradient for a single transition (state-action pair) is given by:\n",
    "    # $\\nabla_{\\theta} \\log \\pi_{\\theta}(a_t|s_t)R_t$\n",
    "    # However, it's easier to work with losses, rather than raw gradients.\n",
    "    # Therefore we construct a loss, that when differentiated, gives us the policy gradient.\n",
    "    # this loss is given by:\n",
    "    # $-\\log \\pi_{\\theta}(a_t|s_t)R_t$\n",
    "\n",
    "    # in (Batch,)\n",
    "    policy_loss_per_example = -torch.log(pi_theta_at_given_st) * R_t\n",
    "\n",
    "    # in (Batch,)\n",
    "    entropy_per_example = -torch.sum(\n",
    "        torch.log(pi_theta_given_st) * pi_theta_given_st, 1\n",
    "    )\n",
    "\n",
    "    # we reward entropy, since excessive certainty indicate the model is 'overfitting'\n",
    "    loss_per_example = policy_loss_per_example - ENTROPY_BONUS * entropy_per_example\n",
    "\n",
    "    # we take the average loss over all examples\n",
    "    return loss_per_example.mean()\n",
    "\n",
    "\n",
    "def train_policygradient(\n",
    "    policy: Policy,\n",
    "    actor_optimizer: torch.optim.Optimizer,\n",
    "    observation_batch: list[npt.NDArray],\n",
    "    action_batch: list[int],\n",
    "    rtg_batch: list[float],\n",
    ") -> float:\n",
    "    # assert that the batch_lengths are the same\n",
    "    assert len(observation_batch) == len(action_batch)\n",
    "    assert len(observation_batch) == len(rtg_batch)\n",
    "\n",
    "    # get device\n",
    "    device = deviceof(policy)\n",
    "\n",
    "    # convert data to tensors on correct device\n",
    "\n",
    "    # in (Batch, Width)\n",
    "    observation_batch_tensor = torch.from_numpy(np.stack(observation_batch)).to(device)\n",
    "\n",
    "    # in (Batch,)\n",
    "    rtg_batch_tensor = torch.tensor(\n",
    "        rtg_batch, dtype=torch.float32, device=device\n",
    "    )\n",
    "\n",
    "    # in (Batch, Action)\n",
    "    chosen_action_tensor = F.one_hot(\n",
    "        torch.tensor(action_batch).to(device).long(), num_classes=NUM_ACTIONS\n",
    "    )\n",
    "\n",
    "    # train actor\n",
    "    actor_optimizer.zero_grad()\n",
    "    action_probs = policy.forward(observation_batch_tensor)\n",
    "    actor_loss = compute_policy_gradient_loss(\n",
    "        action_probs, chosen_action_tensor, rtg_batch_tensor\n",
    "    )\n",
    "    actor_loss.backward()\n",
    "    actor_optimizer.step()\n",
    "\n",
    "    # return the respective losses\n",
    "    return actor_loss.item()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With that, we're done. Let's train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "policy = Policy().to(device)\n",
    "actor_optimizer = torch.optim.Adam(policy.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"MetaDrive-validation-v0\", config={\"use_render\": False, \"horizon\": 500})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ":task(warning): Creating implicit AsyncTaskChain default for AsyncTaskManager TaskManager\n",
      "INFO:/home/fidgetsinner/myworkspace/metadrive/metadrive/envs/base_env.py:Episode ended! Index: 0 Reason: max step \n",
      "INFO:/home/fidgetsinner/myworkspace/metadrive/metadrive/envs/base_env.py:Episode ended! Index: 0 Reason: max step \n",
      "INFO:/home/fidgetsinner/myworkspace/metadrive/metadrive/envs/base_env.py:Episode ended! Index: 0 Reason: max step \n",
      "INFO:/home/fidgetsinner/myworkspace/metadrive/metadrive/envs/base_env.py:Episode ended! Index: 0 Reason: max step \n",
      "INFO:/home/fidgetsinner/myworkspace/metadrive/metadrive/envs/base_env.py:Episode ended! Index: 0 Reason: out_of_road.\n",
      "INFO:/home/fidgetsinner/myworkspace/metadrive/metadrive/envs/base_env.py:Episode ended! Index: 0 Reason: out_of_road.\n",
      "INFO:/home/fidgetsinner/myworkspace/metadrive/metadrive/envs/base_env.py:Episode ended! Index: 0 Reason: out_of_road.\n",
      "INFO:/home/fidgetsinner/myworkspace/metadrive/metadrive/envs/base_env.py:Episode ended! Index: 0 Reason: max step \n",
      "INFO:/home/fidgetsinner/myworkspace/metadrive/metadrive/envs/base_env.py:Episode ended! Index: 0 Reason: max step \n",
      "INFO:/home/fidgetsinner/myworkspace/metadrive/metadrive/envs/base_env.py:Episode ended! Index: 0 Reason: max step \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0, Policy Loss: 0.100, Avg. Returns: 8.882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:/home/fidgetsinner/myworkspace/metadrive/metadrive/envs/base_env.py:Episode ended! Index: 0 Reason: out_of_road.\n",
      "INFO:/home/fidgetsinner/myworkspace/metadrive/metadrive/envs/base_env.py:Episode ended! Index: 0 Reason: max step \n",
      "INFO:/home/fidgetsinner/myworkspace/metadrive/metadrive/envs/base_env.py:Episode ended! Index: 0 Reason: max step \n",
      "INFO:/home/fidgetsinner/myworkspace/metadrive/metadrive/envs/base_env.py:Episode ended! Index: 0 Reason: max step \n",
      "INFO:/home/fidgetsinner/myworkspace/metadrive/metadrive/envs/base_env.py:Episode ended! Index: 0 Reason: max step \n",
      "INFO:/home/fidgetsinner/myworkspace/metadrive/metadrive/envs/base_env.py:Episode ended! Index: 0 Reason: out_of_road.\n",
      "INFO:/home/fidgetsinner/myworkspace/metadrive/metadrive/envs/base_env.py:Episode ended! Index: 0 Reason: max step \n",
      "INFO:/home/fidgetsinner/myworkspace/metadrive/metadrive/envs/base_env.py:Episode ended! Index: 0 Reason: max step \n",
      "INFO:/home/fidgetsinner/myworkspace/metadrive/metadrive/envs/base_env.py:Episode ended! Index: 0 Reason: max step \n",
      "INFO:/home/fidgetsinner/myworkspace/metadrive/metadrive/envs/base_env.py:Episode ended! Index: 0 Reason: max step \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1, Policy Loss: 0.102, Avg. Returns: 8.395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:/home/fidgetsinner/myworkspace/metadrive/metadrive/envs/base_env.py:Episode ended! Index: 0 Reason: max step \n",
      "INFO:/home/fidgetsinner/myworkspace/metadrive/metadrive/envs/base_env.py:Episode ended! Index: 0 Reason: max step \n",
      "INFO:/home/fidgetsinner/myworkspace/metadrive/metadrive/envs/base_env.py:Episode ended! Index: 0 Reason: max step \n",
      "INFO:/home/fidgetsinner/myworkspace/metadrive/metadrive/envs/base_env.py:Episode ended! Index: 0 Reason: max step \n",
      "INFO:/home/fidgetsinner/myworkspace/metadrive/metadrive/envs/base_env.py:Episode ended! Index: 0 Reason: max step \n",
      "INFO:/home/fidgetsinner/myworkspace/metadrive/metadrive/envs/base_env.py:Episode ended! Index: 0 Reason: max step \n",
      "INFO:/home/fidgetsinner/myworkspace/metadrive/metadrive/envs/base_env.py:Episode ended! Index: 0 Reason: out_of_road.\n",
      "INFO:/home/fidgetsinner/myworkspace/metadrive/metadrive/envs/base_env.py:Episode ended! Index: 0 Reason: max step \n",
      "INFO:/home/fidgetsinner/myworkspace/metadrive/metadrive/envs/base_env.py:Episode ended! Index: 0 Reason: max step \n",
      "INFO:/home/fidgetsinner/myworkspace/metadrive/metadrive/envs/base_env.py:Episode ended! Index: 0 Reason: out_of_road.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2, Policy Loss: 0.144, Avg. Returns: 10.672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:/home/fidgetsinner/myworkspace/metadrive/metadrive/envs/base_env.py:Episode ended! Index: 0 Reason: max step \n",
      "INFO:/home/fidgetsinner/myworkspace/metadrive/metadrive/envs/base_env.py:Episode ended! Index: 0 Reason: max step \n",
      "INFO:/home/fidgetsinner/myworkspace/metadrive/metadrive/envs/base_env.py:Episode ended! Index: 0 Reason: max step \n",
      "INFO:/home/fidgetsinner/myworkspace/metadrive/metadrive/envs/base_env.py:Episode ended! Index: 0 Reason: out_of_road.\n",
      "INFO:/home/fidgetsinner/myworkspace/metadrive/metadrive/envs/base_env.py:Episode ended! Index: 0 Reason: max step \n",
      "INFO:/home/fidgetsinner/myworkspace/metadrive/metadrive/envs/base_env.py:Episode ended! Index: 0 Reason: max step \n",
      "INFO:/home/fidgetsinner/myworkspace/metadrive/metadrive/envs/base_env.py:Episode ended! Index: 0 Reason: max step \n",
      "INFO:/home/fidgetsinner/myworkspace/metadrive/metadrive/envs/base_env.py:Episode ended! Index: 0 Reason: max step \n",
      "INFO:/home/fidgetsinner/myworkspace/metadrive/metadrive/envs/base_env.py:Episode ended! Index: 0 Reason: max step \n",
      "INFO:/home/fidgetsinner/myworkspace/metadrive/metadrive/envs/base_env.py:Episode ended! Index: 0 Reason: max step \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3, Policy Loss: 0.153, Avg. Returns: 11.588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:/home/fidgetsinner/myworkspace/metadrive/metadrive/envs/base_env.py:Episode ended! Index: 0 Reason: max step \n",
      "INFO:/home/fidgetsinner/myworkspace/metadrive/metadrive/envs/base_env.py:Episode ended! Index: 0 Reason: max step \n",
      "INFO:/home/fidgetsinner/myworkspace/metadrive/metadrive/envs/base_env.py:Episode ended! Index: 0 Reason: max step \n",
      "INFO:/home/fidgetsinner/myworkspace/metadrive/metadrive/envs/base_env.py:Episode ended! Index: 0 Reason: out_of_road.\n",
      "INFO:/home/fidgetsinner/myworkspace/metadrive/metadrive/envs/base_env.py:Episode ended! Index: 0 Reason: max step \n",
      "INFO:/home/fidgetsinner/myworkspace/metadrive/metadrive/envs/base_env.py:Episode ended! Index: 0 Reason: max step \n",
      "INFO:/home/fidgetsinner/myworkspace/metadrive/metadrive/envs/base_env.py:Episode ended! Index: 0 Reason: max step \n",
      "INFO:/home/fidgetsinner/myworkspace/metadrive/metadrive/envs/base_env.py:Episode ended! Index: 0 Reason: max step \n",
      "INFO:/home/fidgetsinner/myworkspace/metadrive/metadrive/envs/base_env.py:Episode ended! Index: 0 Reason: out_of_road.\n",
      "INFO:/home/fidgetsinner/myworkspace/metadrive/metadrive/envs/base_env.py:Episode ended! Index: 0 Reason: max step \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4, Policy Loss: 0.129, Avg. Returns: 10.599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:/home/fidgetsinner/myworkspace/metadrive/metadrive/envs/base_env.py:Episode ended! Index: 0 Reason: max step \n",
      "INFO:/home/fidgetsinner/myworkspace/metadrive/metadrive/envs/base_env.py:Episode ended! Index: 0 Reason: max step \n",
      "INFO:/home/fidgetsinner/myworkspace/metadrive/metadrive/envs/base_env.py:Episode ended! Index: 0 Reason: max step \n",
      "INFO:/home/fidgetsinner/myworkspace/metadrive/metadrive/envs/base_env.py:Episode ended! Index: 0 Reason: out_of_road.\n",
      "INFO:/home/fidgetsinner/myworkspace/metadrive/metadrive/envs/base_env.py:Episode ended! Index: 0 Reason: out_of_road.\n",
      "INFO:/home/fidgetsinner/myworkspace/metadrive/metadrive/envs/base_env.py:Episode ended! Index: 0 Reason: max step \n",
      "INFO:/home/fidgetsinner/myworkspace/metadrive/metadrive/envs/base_env.py:Episode ended! Index: 0 Reason: max step \n",
      "INFO:/home/fidgetsinner/myworkspace/metadrive/metadrive/envs/base_env.py:Episode ended! Index: 0 Reason: max step \n",
      "INFO:/home/fidgetsinner/myworkspace/metadrive/metadrive/envs/base_env.py:Episode ended! Index: 0 Reason: max step \n"
     ]
    }
   ],
   "source": [
    "TRAIN_EPOCHS = 500\n",
    "EPISODES_PER_BATCH = 10\n",
    "\n",
    "# Train\n",
    "for step in range(TRAIN_EPOCHS):\n",
    "    obs_batch:list[npt.NDArray[np.float32]] = []\n",
    "    act_batch:list[int] = []\n",
    "    rtg_batch:list[float] = []\n",
    "    \n",
    "    trajectory_returns = []\n",
    "\n",
    "    for _ in range(EPISODES_PER_BATCH):\n",
    "        # Collect trajectory\n",
    "        obs_traj, act_traj, rew_traj = collect_trajectory(env, lambda obs: nn_policy(policy, obs))\n",
    "        rtg_traj = rewards_to_go(rew_traj)\n",
    "\n",
    "        # Update batch\n",
    "        obs_batch.extend(obs_traj)\n",
    "        act_batch.extend(act_traj)\n",
    "        rtg_batch.extend(rtg_traj)\n",
    "\n",
    "        # Update trajectory returns\n",
    "        trajectory_returns.append(sum(rew_traj))\n",
    "\n",
    "    policy_loss = train_policygradient(\n",
    "        policy,\n",
    "        actor_optimizer,\n",
    "        obs_batch,\n",
    "        act_batch,\n",
    "        rtg_batch\n",
    "    )\n",
    "\n",
    "    print(f\"Step {step}, Policy Loss: {policy_loss:.3f}, Avg. Returns: {np.mean(trajectory_returns):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize how the policy drives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Known pipe types:\n",
      "  glxGraphicsPipe\n",
      "(1 aux display modules not yet loaded.)\n",
      ":task(warning): Creating implicit AsyncTaskChain default for AsyncTaskManager TaskManager\n",
      "INFO:/home/fidgetsinner/myworkspace/metadrive/metadrive/envs/base_env.py:Episode ended! Index: 0 Reason: max step \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.513679594079509\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"MetaDrive-validation-v0\", config={\"use_render\": True, \"horizon\": 500})\n",
    "obs, act, rew = collect_trajectory(env, lambda obs: nn_policy(policy, obs))\n",
    "env.close()\n",
    "\n",
    "print(\"Reward:\", sum(rew))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For us, we got returns of around 12-14 after training."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metadrive",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
